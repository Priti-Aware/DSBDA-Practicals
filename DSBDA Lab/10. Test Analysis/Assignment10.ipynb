{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533ac220-e3bd-4153-8f7c-cc24b0699182",
   "metadata": {},
   "source": [
    "### Name: Priti Balkrushna Aware\n",
    "### Roll No: 07\n",
    "### Class: TE-B\n",
    "\n",
    "### Assignment No: 10\n",
    "### Text Analytics\n",
    "1. Extract Sample document and apply following document preprocessing methods:\n",
    "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2. Create representation of document by calculating Term Frequency and Inverse Document \n",
    "Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08048fbe-fc48-484f-ac38-1e42fb2ad84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "nltk.download()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f8a715-ba5e-49ce-8a86-0dd31c5b3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"Natural language processing (NLP) is a subfield of linguistics, \n",
    "computer science, and artificial intelligence concerned with the interactions \n",
    "between computers and human language, in particular how to program computers \n",
    "to process and analyze large amounts of natural language data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd5d50d6-1bfc-4b1a-8d64-e3562e228e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(document)\n",
    "print(\"Tokenization:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847408b6-64e2-4362-ad18-abfa4ced87d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('language', 'NN'), (',', ','), ('in', 'IN'), ('particular', 'JJ'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('computers', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"POS Tagging:\", pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb39d94-50c1-472f-9b81-0d7c069b4e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words Removal: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', ',', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"Stop Words Removal:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f47a8f8-356d-4b83-a9fd-02aa21603291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(\"Stemming:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae04e0c-9265-430d-8627-a739bbeb5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"Lemmatization:\", lemmatized_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
